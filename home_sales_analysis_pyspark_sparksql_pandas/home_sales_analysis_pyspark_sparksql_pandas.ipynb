{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5c66af7-614c-44ff-83e1-6c9c07f820dc",
     "showTitle": true,
     "title": "Home sales analysis using Pyspark Dataframe, Spark SQL and Pandas Dataframe"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n|                  id|      date|date_built| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|\n+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n|f8a53099-ba1c-47d...|2022-04-08|      2016|936923|       4|        3|       3167|   11733|     2|         1|  76|\n|7530a2d8-1ae3-451...|2021-06-13|      2013|379628|       2|        2|       2235|   14384|     1|         0|  23|\n|43de979c-0bf0-4c9...|2019-04-12|      2014|417866|       2|        2|       2127|   10575|     2|         0|   0|\n|b672c137-b88c-48b...|2019-10-16|      2016|239895|       2|        2|       1631|   11149|     2|         0|   0|\n|e0726d4d-d595-407...|2022-01-08|      2017|424418|       3|        2|       2249|   13878|     2|         0|   4|\n|5aa00529-0533-46b...|2019-01-30|      2017|218712|       2|        3|       1965|   14375|     2|         0|   7|\n|131492a1-72e2-4a8...|2020-02-08|      2017|419199|       2|        3|       2062|    8876|     2|         0|   6|\n|8d54a71b-c520-44e...|2019-07-21|      2010|323956|       2|        3|       1506|   11816|     1|         0|  25|\n|e81aacfe-17fe-46b...|2020-06-16|      2016|181925|       3|        3|       2137|   11709|     2|         0|  22|\n|2ed8d509-7372-46d...|2021-08-06|      2015|258710|       3|        3|       1918|    9666|     1|         0|  25|\n|f876d86f-3c9f-42b...|2019-02-27|      2011|167864|       3|        3|       2471|   13924|     2|         0|  15|\n|0a2bd445-8508-4d8...|2021-12-30|      2014|337527|       2|        3|       1926|   12556|     1|         0|  23|\n|941bad30-eb49-4a7...|2020-05-09|      2015|229896|       3|        3|       2197|    8641|     1|         0|   3|\n|dd61eb34-6589-4c0...|2021-07-25|      2016|210247|       3|        2|       1672|   11986|     2|         0|  28|\n|f1e4cef7-d151-439...|2019-02-01|      2011|398667|       2|        3|       2331|   11356|     1|         0|   7|\n|ea620c7b-c2f7-4c6...|2021-05-31|      2011|437958|       3|        3|       2356|   11052|     1|         0|  26|\n|f233cb41-6f33-4b0...|2021-07-18|      2016|437375|       4|        3|       1704|   11721|     2|         0|  34|\n|c797ca12-52cd-4b1...|2019-06-08|      2015|288650|       2|        3|       2100|   10419|     2|         0|   7|\n|0cfe57f3-28c2-472...|2019-10-04|      2015|308313|       3|        3|       1960|    9453|     2|         0|   2|\n|4566cd2a-ac6e-435...|2019-07-15|      2016|177541|       3|        3|       2130|   10517|     2|         0|  25|\n+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkFiles\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a85a2ba-c335-4e50-bba2-3817fa56ad2d",
     "showTitle": true,
     "title": "Create a Spark Dataframe"
    }
   },
   "outputs": [],
   "source": [
    "data_source = 'dbfs:/FileStore/homesalesdata/home_sales_revised__1_.csv'\n",
    "homes_df = spark.read.csv(data_source, sep=\",\", header=True)\n",
    "homes_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90e05991-52f2-4709-b525-65c91e551c76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: string (nullable = true)\n |-- date: string (nullable = true)\n |-- date_built: string (nullable = true)\n |-- price: string (nullable = true)\n |-- bedrooms: string (nullable = true)\n |-- bathrooms: string (nullable = true)\n |-- sqft_living: string (nullable = true)\n |-- sqft_lot: string (nullable = true)\n |-- floors: string (nullable = true)\n |-- waterfront: string (nullable = true)\n |-- view: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "homes_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd075ebe-ce4d-45ae-811a-aa863b8810e9",
     "showTitle": true,
     "title": "Create a temporary view for Spark SQL "
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# why? :  A Temporary view in Spark is similar to a real SQL table that contains rows and columns. If you're more comfortable with SQL then you must have to create temporary view with following command and then run SQL query on view.\n",
    "homes_df.createOrReplaceTempView('home_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f9bf9e6-e154-4634-9f4f-ffe7094254d7",
     "showTitle": true,
     "title": "Create a Pandas DataFrame"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id        date date_built   price  \\\n0  f8a53099-ba1c-47d6-9c31-7398aa8f6089  2022-04-08       2016  936923   \n1  7530a2d8-1ae3-4517-9f4a-befe060c4353  2021-06-13       2013  379628   \n2  43de979c-0bf0-4c9f-85ef-96dc27b258d5  2019-04-12       2014  417866   \n3  b672c137-b88c-48bf-9f18-d0a4ac62fb8b  2019-10-16       2016  239895   \n4  e0726d4d-d595-4074-8283-4139a54d0d63  2022-01-08       2017  424418   \n\n  bedrooms bathrooms sqft_living sqft_lot floors waterfront view  \n0        4         3        3167    11733      2          1   76  \n1        2         2        2235    14384      1          0   23  \n2        2         2        2127    10575      2          0    0  \n3        2         2        1631    11149      2          0    0  \n4        3         2        2249    13878      2          0    4  \n"
     ]
    }
   ],
   "source": [
    "pandas_df = homes_df.toPandas()\n",
    "print(pandas_df.head(5))\n",
    "\n",
    "# Little preprocessing in pandas df\n",
    "pandas_df['date'] = pd.to_datetime(pandas_df['date'], format=\"%Y-%m-%d\")   \n",
    "pandas_df['date_built'] = pd.to_datetime(pandas_df['date_built'], format=\"%Y\")     \n",
    "pandas_df['price'] = pd.to_numeric(pandas_df['price'], errors='coerce')\n",
    "pandas_df['bedrooms'] = pd.to_numeric(pandas_df['bedrooms'], errors='coerce')\n",
    "pandas_df['bathrooms'] = pd.to_numeric(pandas_df['bathrooms'], errors='coerce')\n",
    "pandas_df['sqft_living'] = pd.to_numeric(pandas_df['sqft_living'], errors='coerce')\n",
    "pandas_df['sqft_lot'] = pd.to_numeric(pandas_df['sqft_lot'], errors='coerce')\n",
    "pandas_df['floors'] = pd.to_numeric(pandas_df['floors'], errors='coerce')\n",
    "pandas_df['waterfront'] = pd.to_numeric(pandas_df['waterfront'], errors='coerce')\n",
    "pandas_df['view'] = pd.to_numeric(pandas_df['view'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a619bc36-fe42-4759-8b25-0006fb8f4189",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>date_built</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f8a53099-ba1c-47d6-9c31-7398aa8f6089</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>936923</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3167</td>\n",
       "      <td>11733</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7530a2d8-1ae3-4517-9f4a-befe060c4353</td>\n",
       "      <td>2021-06-13</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>379628</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2235</td>\n",
       "      <td>14384</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43de979c-0bf0-4c9f-85ef-96dc27b258d5</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>417866</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2127</td>\n",
       "      <td>10575</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b672c137-b88c-48bf-9f18-d0a4ac62fb8b</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>239895</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1631</td>\n",
       "      <td>11149</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e0726d4d-d595-4074-8283-4139a54d0d63</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>424418</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2249</td>\n",
       "      <td>13878</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>date_built</th>\n      <th>price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>sqft_living</th>\n      <th>sqft_lot</th>\n      <th>floors</th>\n      <th>waterfront</th>\n      <th>view</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f8a53099-ba1c-47d6-9c31-7398aa8f6089</td>\n      <td>2022-04-08</td>\n      <td>2016-01-01</td>\n      <td>936923</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3167</td>\n      <td>11733</td>\n      <td>2</td>\n      <td>1</td>\n      <td>76</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7530a2d8-1ae3-4517-9f4a-befe060c4353</td>\n      <td>2021-06-13</td>\n      <td>2013-01-01</td>\n      <td>379628</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2235</td>\n      <td>14384</td>\n      <td>1</td>\n      <td>0</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>43de979c-0bf0-4c9f-85ef-96dc27b258d5</td>\n      <td>2019-04-12</td>\n      <td>2014-01-01</td>\n      <td>417866</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2127</td>\n      <td>10575</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b672c137-b88c-48bf-9f18-d0a4ac62fb8b</td>\n      <td>2019-10-16</td>\n      <td>2016-01-01</td>\n      <td>239895</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1631</td>\n      <td>11149</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e0726d4d-d595-4074-8283-4139a54d0d63</td>\n      <td>2022-01-08</td>\n      <td>2017-01-01</td>\n      <td>424418</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2249</td>\n      <td>13878</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandas_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04f254ec-a3f8-4b3e-a101-296e27273787",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 33287 entries, 0 to 33286\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype         \n---  ------       --------------  -----         \n 0   id           33287 non-null  object        \n 1   date         33287 non-null  datetime64[ns]\n 2   date_built   33287 non-null  datetime64[ns]\n 3   price        33287 non-null  int64         \n 4   bedrooms     33287 non-null  int64         \n 5   bathrooms    33287 non-null  int64         \n 6   sqft_living  33287 non-null  int64         \n 7   sqft_lot     33287 non-null  int64         \n 8   floors       33287 non-null  int64         \n 9   waterfront   33287 non-null  int64         \n 10  view         33287 non-null  int64         \ndtypes: datetime64[ns](2), int64(8), object(1)\nmemory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "pandas_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01ec9274-1799-4982-b89a-f9b737c1d8c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n|                  id|      date|date_built| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|\n+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n|f8a53099-ba1c-47d...|2022-04-08|      2016|936923|       4|        3|       3167|   11733|     2|         1|  76|\n|7530a2d8-1ae3-451...|2021-06-13|      2013|379628|       2|        2|       2235|   14384|     1|         0|  23|\n+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sqlQuery=\"SELECT * FROM home_sales\").show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23acc3f7-c1cc-4413-ba99-46dcb50a53ed",
     "showTitle": true,
     "title": "1. What is the average price for a four bedroom house sold in each year rounded to two decimal places?"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n|YEAR|AVG_PRICE|\n+----+---------+\n|2022|296363.88|\n|2021|301819.44|\n|2020|298353.78|\n|2019| 300263.7|\n+----+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION : SPARK SQL\n",
    "\n",
    "avg_price_4BR = \"\"\"\n",
    "SELECT \n",
    "    YEAR(DATE) AS YEAR,\n",
    "    ROUND(AVG(price),2) AS AVG_PRICE\n",
    "FROM\n",
    "    HOME_SALES\n",
    "WHERE BEDROOMS = 4\n",
    "GROUP BY\n",
    "    YEAR\n",
    "ORDER BY\n",
    "    YEAR DESC\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sqlQuery=avg_price_4BR).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92d6495c-8c4d-4b84-b8a5-3712602200e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n|year|AVG_PRICE|\n+----+---------+\n|2022|296363.88|\n|2021|301819.44|\n|2020|298353.78|\n|2019| 300263.7|\n+----+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION : PYSPARK DATAFRAME\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "avg_price_4br_spark_df = homes_df.where(col('bedrooms')==4)\\\n",
    "                                .withColumn('YEAR', year(col('date')))\\\n",
    "                                .select('year','bedrooms','price')\\\n",
    "                                .groupBy('year')\\\n",
    "                                .agg(round(avg(\"price\"),2).alias('AVG_PRICE'))\\\n",
    "                                .orderBy(desc('year'))\n",
    "avg_price_4br_spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09399e03-98d3-4e19-8d5b-f70528bd2d8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AVG_PRICE\nyear           \n2022  296363.88\n2021  301819.44\n2020  298353.78\n2019  300263.70\n"
     ]
    }
   ],
   "source": [
    "# # SOLUTION : PANDAS DATAFRAME\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "df_4br = pandas_df[pandas_df['bedrooms']==4][['date','price','bedrooms']]\n",
    "df_4br['year'] = df_4br['date'].dt.strftime('%Y')\n",
    "avg_price = df_4br\\\n",
    "            .groupby('year')\\\n",
    "            .agg(AVG_PRICE=('price', 'mean')).round(2)\\\n",
    "            .sort_values(by='year',ascending=False)\n",
    "\n",
    "print(avg_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68d89fd4-6d01-41d1-b4e8-1ffa13dfa308",
     "showTitle": true,
     "title": "2. What is the average price of a home for each year the home was built that have 3 bedrooms and 3 bathrooms rounded to two decimal places?"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n|YEAR|AVG_PRICE|\n+----+---------+\n|2017|292676.79|\n|2016|290555.07|\n|2015| 288770.3|\n|2014|290852.27|\n|2013|295962.27|\n|2012|293683.19|\n|2011|291117.47|\n|2010|292859.62|\n+----+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION : SPARK SQL\n",
    "\n",
    "\n",
    "avg_price_3bad_3bath = \"\"\"\n",
    "SELECT\n",
    "    YEAR(DATE_BUILT) AS YEAR,\n",
    "    ROUND(AVG(PRICE),2) AS AVG_PRICE\n",
    "FROM\n",
    "    HOME_SALES\n",
    "WHERE \n",
    "    BEDROOMS = 3 AND BATHROOMS = 3\n",
    "GROUP BY\n",
    "    YEAR\n",
    "ORDER BY \n",
    "    YEAR DESC\n",
    "\"\"\"\n",
    "spark.sql(sqlQuery=avg_price_3bad_3bath).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03229262-6b4b-4253-b502-0b92c567c4b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n|year|AVG_PRICE|\n+----+---------+\n|2017|292676.79|\n|2016|290555.07|\n|2015| 288770.3|\n|2014|290852.27|\n|2013|295962.27|\n|2012|293683.19|\n|2011|291117.47|\n|2010|292859.62|\n+----+---------+\n\n"
     ]
    }
   ],
   "source": [
    "#SOLUTION : PYSPARK DATAFRAME\n",
    "\n",
    "\n",
    "bed3_3bath_spark_df = homes_df.where((col('bedrooms')==3) & (col('bathrooms')==3))\\\n",
    "                            .withColumn('YEAR',year(col('date_built')))\\\n",
    "                            .selectExpr('year','bedrooms','bathrooms','price')\\\n",
    "                            .groupBy('year')\\\n",
    "                            .agg(round(avg('price'),2).alias('AVG_PRICE'))\\\n",
    "                            .orderBy(desc('YEAR'))\n",
    "\n",
    "bed3_3bath_spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "960e0708-37a0-4d44-bfbc-96e23c1298cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AVG_PRICE\nyear           \n2017  292676.79\n2016  290555.07\n2015  288770.30\n2014  290852.27\n2013  295962.27\n2012  293683.19\n2011  291117.47\n2010  292859.62\n"
     ]
    }
   ],
   "source": [
    "#SOLUTION : PANDAS DATAFRAME\n",
    "\n",
    "\n",
    "df_3br_3bath = pandas_df[(pandas_df['bedrooms'] == 3) & (pandas_df['bathrooms']==3)][['date_built','bedrooms','bathrooms','price']]\n",
    "\n",
    "df_3br_3bath['year'] = df_3br_3bath['date_built'].dt.strftime('%Y')\n",
    "\n",
    "df_avg = df_3br_3bath\\\n",
    "            .groupby('year')\\\n",
    "            .agg(AVG_PRICE = ('price','mean'))\\\n",
    "            .round(2).sort_values(by = 'year', ascending = False)\n",
    "\n",
    "\n",
    "# print(df_4br_3bath.head)\n",
    "print(df_avg.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82e02102-dc2c-42ea-81f3-b3f3c8bafda2",
     "showTitle": true,
     "title": "3.What is the average price of a home for each year built that have 3 bedrooms, 3 bathrooms, with two floors, and are greater than or equal to 2,000 square feet rounded to two decimal places?"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n|YEAR|AVG_PRICE|\n+----+---------+\n|2017|280317.58|\n|2016| 293965.1|\n|2015|297609.97|\n|2014|298264.72|\n|2013|303676.79|\n|2012|307539.97|\n|2011|276553.81|\n|2010|285010.22|\n+----+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION : SPARK SQL\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    YEAR(date_built) as YEAR,\n",
    "    ROUND(AVG(price),2) as AVG_PRICE\n",
    "FROM\n",
    "    HOME_SALES\n",
    "WHERE\n",
    "    BEDROOMS = 3 AND \n",
    "    BATHROOMS = 3 AND \n",
    "    FLOORS = 2 AND \n",
    "    sqft_living >= 2000\n",
    "GROUP BY\n",
    "    YEAR\n",
    "ORDER BY\n",
    "    YEAR desc\n",
    "\"\"\"\n",
    "spark.sql(sqlQuery=query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7016b198-19d7-4fb9-a2ec-22df9b20fa66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n|date_built|AVG_PRICE|\n+----------+---------+\n|      2017|280317.58|\n|      2016| 293965.1|\n|      2015|297609.97|\n|      2014|298264.72|\n|      2013|303676.79|\n|      2012|307539.97|\n|      2011|276553.81|\n|      2010|285010.22|\n+----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION : PYSPARK DATAFRAME\n",
    "\n",
    "avg_price_3br_3bath_3floor_spark_df = homes_df\\\n",
    "                                        .where((col('bedrooms') == 3) & (col('bathrooms') == 3) & (col('floors') == 2) & (col('sqft_living') >= 2000))\\\n",
    "                                        .select(('date_built'),'price')\\\n",
    "                                        .groupBy('date_built').agg(round(avg('price'),2).alias('AVG_PRICE'))\\\n",
    "                                        .orderBy(desc('date_built'))\n",
    "avg_price_3br_3bath_3floor_spark_df.show()                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c62c2f63-03f0-4fa2-89fa-731842f0eab0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AVG_PRICE\nyear           \n2017  280317.58\n2016  293965.10\n2015  297609.97\n2014  298264.72\n2013  303676.79\n2012  307539.97\n2011  276553.81\n2010  285010.22\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION : PANDAS DATAFRAME\n",
    "\n",
    "\n",
    "pandas_df_3br_3bath_3floor = pandas_df[(pandas_df['bedrooms'] == 3) & (pandas_df['bathrooms'] == 3) & (pandas_df['floors'] == 2) & (pandas_df['sqft_living'] >= 2000) ][['date_built','bedrooms','bathrooms','floors','sqft_living','price']]\n",
    "\n",
    "pandas_df_3br_3bath_3floor['year'] = pandas_df_3br_3bath_3floor['date_built'].dt.strftime('%Y')\n",
    "\n",
    "avg_df = pandas_df_3br_3bath_3floor\\\n",
    "        .groupby('year')\\\n",
    "        .agg(AVG_PRICE = ('price','mean')).round(2)\\\n",
    "        .sort_values(by='year', ascending = False)\n",
    "\n",
    "# print(pandas_df_3br_3bath_3floor.head)\n",
    "print(avg_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66c7e247-1453-456a-88f8-a3379aaadafc",
     "showTitle": true,
     "title": "4. What is the \"view\" rating for the average price of a home, rounded to two decimal places, where the homes are greater than or equal to $350,000? "
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n|VIEW| AVG_PRICE|\n+----+----------+\n|  99|1061201.42|\n|  98|1053739.33|\n|  97|1129040.15|\n|  96|1017815.92|\n|  95| 1054325.6|\n|  94| 1033536.2|\n|  93|1026006.06|\n|  92| 970402.55|\n|  91|1137372.73|\n|  90|1062654.16|\n|  89|1107839.15|\n|  88|1031719.35|\n|  87| 1072285.2|\n|  86|1070444.25|\n|  85|1056336.74|\n|  84|1117233.13|\n|  83|1033965.93|\n|  82| 1063498.0|\n|  81|1053472.79|\n|  80| 991767.38|\n+----+----------+\nonly showing top 20 rows\n\n--- 9.5367431640625e-05 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Although this is a small dataset, determine the run time for this query.\n",
    "\n",
    "# SOLUTION : SPARK SQL\n",
    "\n",
    "view_ratings = \"\"\"\n",
    "SELECT \n",
    "    VIEW,\n",
    "    ROUND(AVG(PRICE),2) AS AVG_PRICE\n",
    "FROM\n",
    "    HOME_SALES\n",
    "GROUP BY\n",
    "    VIEW\n",
    "HAVING \n",
    "    AVG_PRICE > 350000\n",
    "ORDER BY\n",
    "    VIEW DESC\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sqlQuery=view_ratings).show()\n",
    "\n",
    "# FIND RUN TIME OF THE QUERY \n",
    "start_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0e017a7-573a-4d76-a6b1-130dc54cc271",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n|view| AVG_PRICE|\n+----+----------+\n|  99|1061201.42|\n|  98|1053739.33|\n|  97|1129040.15|\n|  96|1017815.92|\n|  95| 1054325.6|\n|  94| 1033536.2|\n|  93|1026006.06|\n|  92| 970402.55|\n|  91|1137372.73|\n|  90|1062654.16|\n|  89|1107839.15|\n|  88|1031719.35|\n|  87| 1072285.2|\n|  86|1070444.25|\n|  85|1056336.74|\n|  84|1117233.13|\n|  83|1033965.93|\n|  82| 1063498.0|\n|  81|1053472.79|\n|  80| 991767.38|\n|  79|1009565.08|\n|  78|1080649.37|\n|  77|1076205.56|\n|  76|1058802.78|\n|  75|1114042.94|\n|  74|  745077.0|\n|  73| 752861.18|\n|  72| 780914.67|\n|  71|  775651.1|\n|  70| 695865.58|\n|  69| 750537.94|\n|  68| 716785.44|\n|  67| 737970.96|\n|  66|  712475.0|\n|  65| 736679.93|\n|  64| 767036.67|\n|  63| 711614.55|\n|  62| 759150.14|\n|  61| 746877.59|\n|  60| 754939.65|\n|  59|  791453.0|\n|  58| 759764.65|\n|  57|  734340.5|\n|  56|  718176.4|\n|  55| 771153.32|\n|  54| 798684.82|\n|  53|  755214.8|\n|  52| 733780.26|\n|  51| 788128.21|\n| 100| 1026669.5|\n+----+----------+\n\n--- 9.369850158691406e-05 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION : SPARK DATAFRAME\n",
    "\n",
    "# NOTE : HAVING doesn't exist in spark dataframe. You express the same logic with agg followed by WHERE\n",
    "\n",
    "view_ratings_spark_df = homes_df.select('view','price')\\\n",
    "                        .groupBy('view')\\\n",
    "                        .agg(round(avg('price'),2).alias('AVG_PRICE'))\\\n",
    "                        .where(col('AVG_PRICE') >= 350000)\\\n",
    "                        .orderBy(desc('view'))\n",
    "\n",
    "view_ratings_spark_df.show(100)\n",
    "\n",
    "# FIND RUN TIME OF THE QUERY \n",
    "start_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c08b317-846e-482f-9e94-f63fdd7c02d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AVERAGE_PRICE\nview               \n51        788128.21\n52        733780.26\n53        755214.80\n54        798684.82\n55        771153.32\n56        718176.40\n57        734340.50\n58        759764.65\n59        791453.00\n60        754939.65\n61        746877.59\n62        759150.14\n63        711614.55\n64        767036.67\n65        736679.93\n66        712475.00\n67        737970.96\n68        716785.44\n69        750537.94\n70        695865.58\n71        775651.10\n72        780914.67\n73        752861.18\n74        745077.00\n75       1114042.94\n76       1058802.78\n77       1076205.56\n78       1080649.37\n79       1009565.08\n80        991767.38\n81       1053472.79\n82       1063498.00\n83       1033965.92\n84       1117233.13\n85       1056336.74\n86       1070444.25\n87       1072285.20\n88       1031719.35\n89       1107839.15\n90       1062654.16\n91       1137372.73\n92        970402.55\n93       1026006.06\n94       1033536.20\n95       1054325.60\n96       1017815.92\n97       1129040.15\n98       1053739.33\n99       1061201.42\n100      1026669.50\n--- 8.249282836914062e-05 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION : PANDAS DATAFRAME\n",
    "\n",
    "view_ratings_pandas_df = pandas_df[['view', 'price']]\\\n",
    "                        .groupby('view')\\\n",
    "                        .agg(AVERAGE_PRICE=('price','mean')).round(2)\n",
    "\n",
    "filter_records = view_ratings_pandas_df[view_ratings_pandas_df['AVERAGE_PRICE'] >= 350000]\n",
    "\n",
    "print(filter_records)\n",
    "\n",
    "# FIND RUN TIME OF THE QUERY \n",
    "start_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67da53c3-bd9b-4b2c-9c2e-2f2dd70e50d8",
     "showTitle": true,
     "title": "Cache Table"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[20]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "# Cache the temporary table home_sales\n",
    "spark.sql(sqlQuery='cache table HOME_SALES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffd99a52-a0e7-491c-8894-e61ff1c4ceeb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[21]: True"
     ]
    }
   ],
   "source": [
    "# check if the table is cached\n",
    "spark.catalog.isCached('HOME_SALES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fedf411-8dc2-4837-9f8f-6bd27f37ac00",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n|VIEW| AVG_PRICE|\n+----+----------+\n|  99|1061201.42|\n|  98|1053739.33|\n|  97|1129040.15|\n|  96|1017815.92|\n|  95| 1054325.6|\n|  94| 1033536.2|\n|  93|1026006.06|\n|  92| 970402.55|\n|  91|1137372.73|\n|  90|1062654.16|\n|  89|1107839.15|\n|  88|1031719.35|\n|  87| 1072285.2|\n|  86|1070444.25|\n|  85|1056336.74|\n|  84|1117233.13|\n|  83|1033965.93|\n|  82| 1063498.0|\n|  81|1053472.79|\n|  80| 991767.38|\n+----+----------+\nonly showing top 20 rows\n\n--- 0.00013756752014160156 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 5. Using the cached data, run the query that filters out the view ratings with average price greater than or equal to $350,000. Determine the runtime and compare it to uncached runtime.\n",
    "\n",
    "\n",
    "# SOLUTION : SPARK SQL\n",
    "\n",
    "view_ratings = \"\"\"\n",
    "SELECT \n",
    "    VIEW,\n",
    "    ROUND(AVG(PRICE),2) AS AVG_PRICE\n",
    "FROM\n",
    "    HOME_SALES\n",
    "GROUP BY\n",
    "    VIEW\n",
    "HAVING \n",
    "    AVG_PRICE > 350000\n",
    "ORDER BY\n",
    "    VIEW DESC\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sqlQuery=view_ratings).show()\n",
    "\n",
    "# FIND RUN TIME OF THE QUERY \n",
    "start_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6512d32e-0f97-4079-9981-74212dadbe98",
     "showTitle": true,
     "title": "Partition by the \"date_built\" field on the formatted parquet home sales data"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "homes_df.write.partitionBy('date_built').parquet('parquet_home_sales', mode='overwrite')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d23895e-3951-4141-9492-27fcc546282f",
     "showTitle": true,
     "title": "Read the formated Parquet Data"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.head of DataFrame[id: string, date: string, price: string, bedrooms: string, bathrooms: string, sqft_living: string, sqft_lot: string, floors: string, waterfront: string, view: string, date_built: int]>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parquet_df = spark.read.parquet('dbfs:/parquet_home_sales')\n",
    "print(parquet_df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbe34875-b788-4612-92e3-4fb7d4c219b9",
     "showTitle": true,
     "title": "Create a temporary table for the parquet data."
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[30]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "spark.sql(sqlQuery='uncache table HOME_SALES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee3968ba-d24d-431d-b2b6-d1b96c644b4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n|view| AVG_PRICE|\n+----+----------+\n|  99|1061201.42|\n|  98|1053739.33|\n|  97|1129040.15|\n|  96|1017815.92|\n|  95| 1054325.6|\n|  94| 1033536.2|\n|  93|1026006.06|\n|  92| 970402.55|\n|  91|1137372.73|\n|  90|1062654.16|\n|  89|1107839.15|\n|  88|1031719.35|\n|  87| 1072285.2|\n|  86|1070444.25|\n|  85|1056336.74|\n|  84|1117233.13|\n|  83|1033965.93|\n|  82| 1063498.0|\n|  81|1053472.79|\n|  80| 991767.38|\n|  79|1009565.08|\n|  78|1080649.37|\n|  77|1076205.56|\n|  76|1058802.78|\n|  75|1114042.94|\n|  74|  745077.0|\n|  73| 752861.18|\n|  72| 780914.67|\n|  71|  775651.1|\n|  70| 695865.58|\n|  69| 750537.94|\n|  68| 716785.44|\n|  67| 737970.96|\n|  66|  712475.0|\n|  65| 736679.93|\n|  64| 767036.67|\n|  63| 711614.55|\n|  62| 759150.14|\n|  61| 746877.59|\n|  60| 754939.65|\n|  59|  791453.0|\n|  58| 759764.65|\n|  57|  734340.5|\n|  56|  718176.4|\n|  55| 771153.32|\n|  54| 798684.82|\n|  53|  755214.8|\n|  52| 733780.26|\n|  51| 788128.21|\n| 100| 1026669.5|\n+----+----------+\n\n--- 0.0001983642578125 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Run the query that filters out the view ratings with average price of greater than or eqaul to $350,000 with the parquet DataFrame. Round your average to two decimal places.\n",
    "\n",
    "# Determine the runtime and compare it to the cached version.\n",
    "\n",
    "view_ratings_spark_df = parquet_df.select('view','price')\\\n",
    "                        .groupBy('view')\\\n",
    "                        .agg(round(avg('price'),2).alias('AVG_PRICE'))\\\n",
    "                        .where(col('AVG_PRICE') >= 350000)\\\n",
    "                        .orderBy(desc('view'))\n",
    "\n",
    "view_ratings_spark_df.show(100)\n",
    "\n",
    "# FIND RUN TIME OF THE QUERY \n",
    "start_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "021d95ef-77e4-4bf1-8f89-d703792c42d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not cached\n"
     ]
    }
   ],
   "source": [
    "# Check if the home_sales is no longer cached\n",
    "if spark.catalog.isCached('home_sales'):\n",
    "  print('home_sales is cached')\n",
    "else:\n",
    "  print('not cached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15f43093-c067-4d2d-8402-e47e20117e5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "home_sales_analysis_pyspark_sparksql_pandas",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
